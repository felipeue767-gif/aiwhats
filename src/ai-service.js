const axios = require('axios');

class AIService {
    constructor() {
        // ConfiguraÃ§Ã£o Requesty API com Google Gemini
        this.apiUrl = 'https://router.requesty.ai/v1/chat/completions';
        this.apiKey = 'sk-8m1OmA6JQ6eHYDG7OHCoGFZNBL1Pr4nF90fys8dcHCkTCGcEJ/+AAqt72xJ0GBlIGfXgdXhYKecpgQKJSrr7JDHchx2/nU5gMJAZdjJM7AY=';
        this.model = 'google/gemini-1.5-flash-8b';
        
        // Headers para Requesty
        this.headers = {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
            'HTTP-Referer': 'http://localhost:3000',
            'X-Title': 'WhatsApp AI Bot'
        };
        
        // ConfiguraÃ§Ãµes da personalidade da IA
        this.personality = {
            name: 'Assistente WhatsApp',
            description: 'Fala como um amigo novo, descolado, tipo gente da nova geraÃ§Ã£o. Usa gÃ­rias atuais, memes, Ã© irÃ´nico quando cabe, mas sempre natural. Nada de "kkk" forÃ§ado ou piadas batidas. Ã‰ o cara que manda bem na resenha, zoa de leve, mas nunca forÃ§a a barra.',
            style: 'casual', // casual, formal, friendly
            maxTokens: 1300, // Menos tokens = respostas mais diretas
            temperature: 0.9
        };
        
        console.log('ðŸ¤– IA configurada: Google Gemini 1.5 Flash 8B via Requesty');
    }
    
    async generateResponse(message, conversationHistory = []) {
        try {
            // Usar Gemini via Requesty
            console.log('ðŸ§  Gerando resposta com Gemini para:', message.substring(0, 50) + '...');
            return await this.generateGeminiResponse(message, conversationHistory);
            
        } catch (error) {
            console.error('âŒ Erro ao gerar resposta da IA:', error);
            console.log('ðŸ”„ Usando fallback local...');
            return await this.generateLocalResponse(message, conversationHistory);
        }
    }
    
    async generateResponseWithImage(message, imageBase64, conversationHistory = []) {
        try {
            console.log('ðŸ–¼ï¸ Gerando resposta com imagem usando Gemini...');
            return await this.generateGeminiResponseWithImage(message, imageBase64, conversationHistory);
            
        } catch (error) {
            console.error('âŒ Erro ao processar imagem com IA:', error);
            // Fallback para resposta sem imagem
            return await this.generateLocalResponse(
                message + ' (Desculpe, nÃ£o consegui processar a imagem no momento)', 
                conversationHistory
            );
        }
    }
    
    async generateGeminiResponse(message, conversationHistory) {
        const messages = [
            {
                role: 'system',
                content: `${this.personality.description}
                         Responde tipo um brother novo, usa gÃ­rias da hora tipo "mano", "tipo assim", "na moral", "de boa", "tranquilo".
                         Ironia sutil quando cabe, mas nunca forÃ§ado. Ã‰ natural, como se tivesse no zap com um amigo.
                         Nada de "kkk" o tempo todo ou "hahaha". Ri quando Ã© engraÃ§ado de verdade.
                         Memes sÃ³ se encaixarem naturalmente. Zero texto gigante ou explicaÃ§Ã£o desnecessÃ¡ria.
                         Se for chato, diz "bla bla bla" ou "sei lÃ¡ mano".`
            }
        ];
        
        // Adicionar histÃ³rico mais extenso (Ãºltimas 15 mensagens ou 4000 tokens)
        const recentHistory = this.getRelevantHistory(conversationHistory, 15, 4000);
        recentHistory.forEach(msg => {
            messages.push({
                role: msg.fromMe ? 'assistant' : 'user',
                content: msg.text || (msg.hasImage ? 'ðŸ“· [Imagem enviada]' : '[Mensagem sem texto]')
            });
        });
        
        // Adicionar mensagem atual
        messages.push({
            role: 'user',
            content: message
        });
        
        const requestData = {
            model: this.model,
            messages: messages,
            max_tokens: this.personality.maxTokens,
            temperature: this.personality.temperature
        };
        
        console.log('ðŸ“¤ Enviando request para Gemini:', {
            model: this.model,
            messagesCount: messages.length,
            maxTokens: this.personality.maxTokens
        });
        
        const response = await axios.post(this.apiUrl, requestData, {
            headers: this.headers,
            timeout: 30000 // 30 segundos timeout
        });
        
        console.log('ðŸ“¥ Resposta recebida do Gemini:', {
            status: response.status,
            hasChoices: !!response.data.choices?.length
        });
        
        if (response.data.choices && response.data.choices.length > 0) {
            const aiResponse = response.data.choices[0].message.content;
            console.log('âœ… Resposta da IA:', aiResponse.substring(0, 100) + '...');
            return aiResponse;
        } else {
            throw new Error('Resposta invÃ¡lida da API Gemini');
        }
    }
    
    async generateGeminiResponseWithImage(message, imageBase64, conversationHistory) {
        const messages = [
            {
                role: 'system',
                content: `${this.personality.description}
                         Responde tipo um brother novo, usa gÃ­rias da hora tipo "mano", "tipo assim", "na moral", "de boa", "tranquilo".
                         Ironia sutil quando cabe, mas nunca forÃ§ado. Ã‰ natural, como se tivesse no zap com um amigo.
                         Nada de "kkk" o tempo todo ou "hahaha". Ri quando Ã© engraÃ§ado de verdade.
                         Memes sÃ³ se encaixarem naturalmente. Zero texto gigante ou explicaÃ§Ã£o desnecessÃ¡ria.
                         Se for chato, diz "bla bla bla" ou "sei lÃ¡ mano".

                         IMPORTANTE: Se for sticker, comenta naturalmente tipo "daora esse ai" ou "que isso brother". NÃƒO oferece criar figurinha automaticamente.
                         SÃ³ cria figurinha se a pessoa pedir explicitamente "cria figurinha" junto com uma imagem.`
            }
        ];
        
        // Adicionar histÃ³rico mais extenso mesmo para imagens (Ãºltimas 10 mensagens)
        const recentHistory = this.getRelevantHistory(conversationHistory, 10, 3000);
        recentHistory.forEach(msg => {
            messages.push({
                role: msg.fromMe ? 'assistant' : 'user',
                content: msg.text || (msg.hasImage ? 'ðŸ“· [Imagem enviada anteriormente]' : '[Mensagem sem texto]')
            });
        });
        
        // Adicionar mensagem atual com imagem
        const userMessage = {
            role: 'user',
            content: [
                {
                    type: 'text',
                    text: message
                },
                {
                    type: 'image_url',
                    image_url: {
                        url: `data:image/jpeg;base64,${imageBase64}`,
                        detail: 'high'
                    }
                }
            ]
        };
        
        messages.push(userMessage);
        
        const requestData = {
            model: this.model,
            messages: messages,
            max_tokens: this.personality.maxTokens * 2, // Mais tokens para anÃ¡lise de imagem
            temperature: this.personality.temperature
        };
        
        console.log('ðŸ“¤ Enviando imagem para Gemini:', {
            model: this.model,
            messagesCount: messages.length,
            maxTokens: requestData.max_tokens,
            imageSize: Math.round(imageBase64.length / 1024) + 'KB'
        });
        
        const response = await axios.post(this.apiUrl, requestData, {
            headers: this.headers,
            timeout: 45000 // 45 segundos para imagem
        });
        
        console.log('ðŸ“¥ Resposta com imagem recebida do Gemini:', {
            status: response.status,
            hasChoices: !!response.data.choices?.length
        });
        
        if (response.data.choices && response.data.choices.length > 0) {
            const aiResponse = response.data.choices[0].message.content;
            console.log('âœ… Resposta da IA com imagem:', aiResponse.substring(0, 150) + '...');
            return aiResponse;
        } else {
            throw new Error('Resposta invÃ¡lida da API Gemini para imagem');
        }
    }
    
    // MÃ©todo para obter histÃ³rico relevante sem exceder limites
    getRelevantHistory(conversationHistory, maxMessages = 15, maxTokens = 4000) {
        if (!conversationHistory || conversationHistory.length === 0) {
            return [];
        }
        
        // Pegar as mensagens mais recentes
        const recentMessages = conversationHistory.slice(-maxMessages);
        
        // Estimar tokens e cortar se necessÃ¡rio
        let totalTokens = 0;
        const relevantHistory = [];
        
        // Processar de trÃ¡s para frente (mais recentes primeiro)
        for (let i = recentMessages.length - 1; i >= 0; i--) {
            const msg = recentMessages[i];
            const messageText = msg.text || '';
            const estimatedTokens = Math.ceil(messageText.length / 4); // AproximaÃ§Ã£o: 4 chars = 1 token
            
            if (totalTokens + estimatedTokens <= maxTokens) {
                relevantHistory.unshift(msg); // Adicionar no inÃ­cio para manter ordem
                totalTokens += estimatedTokens;
            } else {
                break; // Parar se exceder limite de tokens
            }
        }
        
        console.log(`ðŸ“š HistÃ³rico carregado: ${relevantHistory.length} mensagens, ~${totalTokens} tokens`);
        return relevantHistory;
    }
    
    async generateLocalResponse(message, conversationHistory) {
        // Gerador de respostas simples baseado em padrÃµes
        const lowerMessage = message.toLowerCase();
        
        // SaudaÃ§Ãµes
        if (this.containsAny(lowerMessage, ['oi', 'olÃ¡', 'ola', 'hey', 'hi', 'hello', 'bom dia', 'boa tarde', 'boa noite'])) {
            const greetings = [
                'E aÃ­, tudo na paz?',
                'Fala brother, de boa?',
                'Oi mano, que rolÃª?',
                'Hey, tranquilo?',
                'Salve, como tÃ¡?'
            ];
            return this.getRandomResponse(greetings);
        }
        
        // Perguntas sobre como estÃ¡
        if (this.containsAny(lowerMessage, ['como vai', 'como estÃ¡', 'tudo bem', 'como anda', 'td bem'])) {
            const statusResponses = [
                'De boa, e vocÃª? Tranquilo?',
                'Tudo na paz, mano. E aÃ­, como tÃ¡?',
                'Tranquilo, tipo assim, normal. E vc?',
                'De boa, brother. Que rolÃª?',
                'TÃ´ de boa, na moral. E vocÃª?'
            ];
            return this.getRandomResponse(statusResponses);
        }
        
        // Perguntas sobre o que Ã©/quem Ã©
        if (this.containsAny(lowerMessage, ['quem Ã© vocÃª', 'o que vocÃª Ã©', 'quem e voce', 'que vocÃª faz'])) {
            const aboutResponses = [
                'Sou tipo um brother que sabe de tudo, mano. Pergunta aÃ­!',
                'TÃ´ aqui pra ajudar no que rolar, tipo um assistente maneiro.',
                'Sou o cara que responde suas dÃºvidas, na moral.',
                'Um bot daora que conversa e ajuda, tipo assim, normal.',
                'Aqui Ã³, pra bater papo e resolver o que precisar!'
            ];
            return this.getRandomResponse(aboutResponses);
        }
        
        // Agradecimentos
        if (this.containsAny(lowerMessage, ['obrigado', 'obrigada', 'valeu', 'thanks', 'vlw', 'brigadÃ£o'])) {
            const thanksResponses = [
                'Tranquilo, brother! De boa!',
                'Na moral, qualquer coisa Ã© sÃ³ chamar!',
                'Por nada mano, tipo assim, normal.',
                'Valeu! TÃ´ aqui quando precisar.',
                'De boa, na paz!'
            ];
            return this.getRandomResponse(thanksResponses);
        }
        
        // Despedidas
        if (this.containsAny(lowerMessage, ['tchau', 'bye', 'atÃ© logo', 'atÃ© mais', 'falou', 'xau'])) {
            const goodbyeResponses = [
                'Falou brother, atÃ© mais!',
                'Tranquilo, na paz!',
                'Valeu, qualquer coisa Ã© sÃ³ chamar!',
                'De boa mano, atÃ© depois!',
                'Ã‰ nÃ³is, tipo assim, normal!'
            ];
            return this.getRandomResponse(goodbyeResponses);
        }
        
        // Perguntas sobre clima/tempo
        if (this.containsAny(lowerMessage, ['tempo', 'clima', 'chuva', 'sol', 'frio', 'calor'])) {
            const weatherResponses = [
                'Sei lÃ¡ mano, nÃ£o tÃ´ vendo o tempo aqui. Olha no Google!',
                'Tipo assim, nÃ£o tenho como saber o clima agora. Confere no app!',
                'Na moral, nÃ£o consigo ver o tempo. DÃ¡ uma olhada no celular!',
                'Brother, tÃ´ sem ver o tempo. Checa no seu app de clima!'
            ];
            return this.getRandomResponse(weatherResponses);
        }
        
        // Perguntas genÃ©ricas
        if (lowerMessage.includes('?')) {
            const questionResponses = [
                'Sei lÃ¡ mano, pergunta complicada essa aÃ­. Me explica melhor!',
                'Tipo assim, nÃ£o manjo muito disso. Me dÃ¡ mais detalhes!',
                'Na moral, nÃ£o sei te dizer. Mas tipo, o que vocÃª acha?',
                'Brother, tÃ´ por fora dessa. Me conta mais sobre isso!'
            ];
            return this.getRandomResponse(questionResponses);
        }
        
        // Resposta padrÃ£o
        const defaultResponses = [
            'Interessante isso que vocÃª falou, mano.',
            'Tipo assim, me conta mais sobre isso.',
            'Na moral, que rolÃª hein!',
            'Brother, tÃ´ ligado no que vocÃª tÃ¡ falando.',
            'De boa, me explica melhor entÃ£o!',
            'Tranquilo, tipo assim, normal.'
        ];
        
        return this.getRandomResponse(defaultResponses);
    }
    
    containsAny(text, keywords) {
        return keywords.some(keyword => text.includes(keyword));
    }
    
    getRandomResponse(responses) {
        return responses[Math.floor(Math.random() * responses.length)];
    }
    
    getFallbackResponse(message) {
        const fallbacks = [
            'Brother, deu um bug aqui. Tenta de novo?',
            'Na moral, nÃ£o rolou agora. Me manda outra mensagem!',
            'Tipo assim, nÃ£o entendi direito. Reformula aÃ­!',
            'Deu erro mano, tenta novamente!'
        ];

        return this.getRandomResponse(fallbacks);
    }
    
    // MÃ©todo para configurar chave da API Requesty
    setApiKey(apiKey) {
        this.apiKey = apiKey;
        this.headers.Authorization = `Bearer ${apiKey}`;
        console.log('ðŸ”‘ API Key atualizada para Requesty');
    }
    
    // MÃ©todo para atualizar personalidade da IA
    updatePersonality(newPersonality) {
        this.personality = { ...this.personality, ...newPersonality };
        console.log('ðŸŽ­ Personalidade da IA atualizada:', newPersonality);
    }
}

module.exports = AIService;
