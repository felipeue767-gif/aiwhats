const axios = require('axios');

class AIService {
    constructor() {
        // Configura√ß√£o Requesty API com Google Gemini
        this.apiUrl = 'https://router.requesty.ai/v1/chat/completions';
        this.apiKey = 'sk-8m1OmA6JQ6eHYDG7OHCoGFZNBL1Pr4nF90fys8dcHCkTCGcEJ/+AAqt72xJ0GBlIGfXgdXhYKecpgQKJSrr7JDHchx2/nU5gMJAZdjJM7AY=';
        this.model = 'google/gemini-1.5-flash-8b';
        
        // Headers para Requesty
        this.headers = {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
            'HTTP-Referer': 'http://localhost:3000',
            'X-Title': 'WhatsApp AI Bot'
        };
        
        // Configura√ß√µes da personalidade da IA
        this.personality = {
            name: 'Assistente WhatsApp',
            description: 'Fala como um amigo novo, descolado, tipo gente da nova gera√ß√£o. Usa g√≠rias atuais, memes, √© ir√¥nico quando cabe, mas sempre natural. Nada de "kkk" for√ßado ou piadas batidas. √â o cara que manda bem na resenha, zoa de leve, mas nunca for√ßa a barra.',
            style: 'casual', // casual, formal, friendly
            maxTokens: 1300, // Menos tokens = respostas mais diretas
            temperature: 0.9
        };
        
        console.log('ü§ñ IA configurada: Google Gemini 1.5 Flash 8B via Requesty');
    }
    
    async generateResponse(message, conversationHistory = []) {
        try {
            // Usar Gemini via Requesty
            console.log('üß† Gerando resposta com Gemini para:', message.substring(0, 50) + '...');
            return await this.generateGeminiResponse(message, conversationHistory);
            
        } catch (error) {
            console.error('‚ùå Erro ao gerar resposta da IA:', error);
            console.log('üîÑ Usando fallback local...');
            return await this.generateLocalResponse(message, conversationHistory);
        }
    }
    
    async generateResponseWithImage(message, imageBase64, conversationHistory = []) {
        try {
            console.log('üñºÔ∏è Gerando resposta com imagem usando Gemini...');
            return await this.generateGeminiResponseWithImage(message, imageBase64, conversationHistory);
            
        } catch (error) {
            console.error('‚ùå Erro ao processar imagem com IA:', error);
            // Fallback para resposta sem imagem
            return await this.generateLocalResponse(
                message + ' (Desculpe, n√£o consegui processar a imagem no momento)', 
                conversationHistory
            );
        }
    }
    
    async generateGeminiResponse(message, conversationHistory) {
        const messages = [
            {
                role: 'system',
                content: `${this.personality.description}
                         Responde tipo um brother novo, usa g√≠rias da hora tipo "mano", "tipo assim", "na moral", "de boa", "tranquilo".
                         Ironia sutil quando cabe, mas nunca for√ßado. √â natural, como se tivesse no zap com um amigo.
                         Nada de "kkk" o tempo todo ou "hahaha". Ri quando √© engra√ßado de verdade.
                         Memes s√≥ se encaixarem naturalmente. Zero texto gigante ou explica√ß√£o desnecess√°ria.
                         Se for chato, diz "bla bla bla" ou "sei l√° mano".`
            }
        ];
        
        // Adicionar hist√≥rico mais extenso (√∫ltimas 15 mensagens ou 4000 tokens)
        const recentHistory = this.getRelevantHistory(conversationHistory, 15, 4000);
        recentHistory.forEach(msg => {
            messages.push({
                role: msg.fromMe ? 'assistant' : 'user',
                content: msg.text || (msg.hasImage ? 'üì∑ [Imagem enviada]' : '[Mensagem sem texto]')
            });
        });
        
        // Adicionar mensagem atual
        messages.push({
            role: 'user',
            content: message
        });
        
        const requestData = {
            model: this.model,
            messages: messages,
            max_tokens: this.personality.maxTokens,
            temperature: this.personality.temperature
        };
        
        console.log('üì§ Enviando request para Gemini:', {
            model: this.model,
            messagesCount: messages.length,
            maxTokens: this.personality.maxTokens
        });
        
        const response = await axios.post(this.apiUrl, requestData, {
            headers: this.headers,
            timeout: 30000 // 30 segundos timeout
        });
        
        console.log('üì• Resposta recebida do Gemini:', {
            status: response.status,
            hasChoices: !!response.data.choices?.length
        });
        
        if (response.data.choices && response.data.choices.length > 0) {
            const aiResponse = response.data.choices[0].message.content;
            console.log('‚úÖ Resposta da IA:', aiResponse.substring(0, 100) + '...');
            return aiResponse;
        } else {
            throw new Error('Resposta inv√°lida da API Gemini');
        }
    }
    
    async generateGeminiResponseWithImage(message, imageBase64, conversationHistory) {
        const messages = [
            {
                role: 'system',
                content: `${this.personality.description}
                         Responde tipo um brother novo, usa g√≠rias da hora tipo "mano", "tipo assim", "na moral", "de boa", "tranquilo".
                         Ironia sutil quando cabe, mas nunca for√ßado. √â natural, como se tivesse no zap com um amigo.
                         Nada de "kkk" o tempo todo ou "hahaha". Ri quando √© engra√ßado de verdade.
                         Memes s√≥ se encaixarem naturalmente. Zero texto gigante ou explica√ß√£o desnecess√°ria.
                         Se for chato, diz "bla bla bla" ou "sei l√° mano".

                         IMPORTANTE: Se for sticker, comenta naturalmente tipo "daora esse ai" ou "que isso brother". N√ÉO oferece criar figurinha automaticamente.
                         S√≥ cria figurinha se a pessoa pedir explicitamente "cria figurinha" junto com uma imagem.`
            }
        ];
        
        // Adicionar hist√≥rico mais extenso mesmo para imagens (√∫ltimas 10 mensagens)
        const recentHistory = this.getRelevantHistory(conversationHistory, 10, 3000);
        recentHistory.forEach(msg => {
            messages.push({
                role: msg.fromMe ? 'assistant' : 'user',
                content: msg.text || (msg.hasImage ? 'üì∑ [Imagem enviada anteriormente]' : '[Mensagem sem texto]')
            });
        });
        
        // Adicionar mensagem atual com imagem
        const userMessage = {
            role: 'user',
            content: [
                {
                    type: 'text',
                    text: message
                },
                {
                    type: 'image_url',
                    image_url: {
                        url: `data:image/jpeg;base64,${imageBase64}`,
                        detail: 'high'
                    }
                }
            ]
        };
        
        messages.push(userMessage);
        
        const requestData = {
            model: this.model,
            messages: messages,
            max_tokens: this.personality.maxTokens * 2, // Mais tokens para an√°lise de imagem
            temperature: this.personality.temperature
        };
        
        console.log('üì§ Enviando imagem para Gemini:', {
            model: this.model,
            messagesCount: messages.length,
            maxTokens: requestData.max_tokens,
            imageSize: Math.round(imageBase64.length / 1024) + 'KB'
        });
        
        const response = await axios.post(this.apiUrl, requestData, {
            headers: this.headers,
            timeout: 45000 // 45 segundos para imagem
        });
        
        console.log('üì• Resposta com imagem recebida do Gemini:', {
            status: response.status,
            hasChoices: !!response.data.choices?.length
        });
        
        if (response.data.choices && response.data.choices.length > 0) {
            const aiResponse = response.data.choices[0].message.content;
            console.log('‚úÖ Resposta da IA com imagem:', aiResponse.substring(0, 150) + '...');
            return aiResponse;
        } else {
            throw new Error('Resposta inv√°lida da API Gemini para imagem');
        }
    }
    
    // M√©todo para obter hist√≥rico relevante sem exceder limites
    getRelevantHistory(conversationHistory, maxMessages = 15, maxTokens = 4000) {
        if (!conversationHistory || conversationHistory.length === 0) {
            return [];
        }
        
        // Pegar as mensagens mais recentes
        const recentMessages = conversationHistory.slice(-maxMessages);
        
        // Estimar tokens e cortar se necess√°rio
        let totalTokens = 0;
        const relevantHistory = [];
        
        // Processar de tr√°s para frente (mais recentes primeiro)
        for (let i = recentMessages.length - 1; i >= 0; i--) {
            const msg = recentMessages[i];
            const messageText = msg.text || '';
            const estimatedTokens = Math.ceil(messageText.length / 4); // Aproxima√ß√£o: 4 chars = 1 token
            
            if (totalTokens + estimatedTokens <= maxTokens) {
                relevantHistory.unshift(msg); // Adicionar no in√≠cio para manter ordem
                totalTokens += estimatedTokens;
            } else {
                break; // Parar se exceder limite de tokens
            }
        }
        
        console.log(`üìö Hist√≥rico carregado: ${relevantHistory.length} mensagens, ~${totalTokens} tokens`);
        return relevantHistory;
    }
    
    async generateLocalResponse(message, conversationHistory) {
        // Gerador de respostas simples baseado em padr√µes
        const lowerMessage = message.toLowerCase();
        
        // Sauda√ß√µes
        if (this.containsAny(lowerMessage, ['oi', 'ol√°', 'ola', 'hey', 'hi', 'hello', 'bom dia', 'boa tarde', 'boa noite'])) {
            const greetings = [
                'E a√≠, tudo na paz?',
                'Fala brother, de boa?',
                'Oi mano, que rol√™?',
                'Hey, tranquilo?',
                'Salve, como t√°?'
            ];
            return this.getRandomResponse(greetings);
        }
        
        // Perguntas sobre como est√°
        if (this.containsAny(lowerMessage, ['como vai', 'como est√°', 'tudo bem', 'como anda', 'td bem'])) {
            const statusResponses = [
                'De boa, e voc√™? Tranquilo?',
                'Tudo na paz, mano. E a√≠, como t√°?',
                'Tranquilo, tipo assim, normal. E vc?',
                'De boa, brother. Que rol√™?',
                'T√¥ de boa, na moral. E voc√™?'
            ];
            return this.getRandomResponse(statusResponses);
        }
        
        // Perguntas sobre o que √©/quem √©
        if (this.containsAny(lowerMessage, ['quem √© voc√™', 'o que voc√™ √©', 'quem e voce', 'que voc√™ faz'])) {
            const aboutResponses = [
                'Sou tipo um brother que sabe de tudo, mano. Pergunta a√≠!',
                'T√¥ aqui pra ajudar no que rolar, tipo um assistente maneiro.',
                'Sou o cara que responde suas d√∫vidas, na moral.',
                'Um bot daora que conversa e ajuda, tipo assim, normal.',
                'Aqui √≥, pra bater papo e resolver o que precisar!'
            ];
            return this.getRandomResponse(aboutResponses);
        }
        
        // Agradecimentos
        if (this.containsAny(lowerMessage, ['obrigado', 'obrigada', 'valeu', 'thanks', 'vlw', 'brigad√£o'])) {
            const thanksResponses = [
                'Tranquilo, brother! De boa!',
                'Na moral, qualquer coisa √© s√≥ chamar!',
                'Por nada mano, tipo assim, normal.',
                'Valeu! T√¥ aqui quando precisar.',
                'De boa, na paz!'
            ];
            return this.getRandomResponse(thanksResponses);
        }
        
        // Despedidas
        if (this.containsAny(lowerMessage, ['tchau', 'bye', 'at√© logo', 'at√© mais', 'falou', 'xau'])) {
            const goodbyeResponses = [
                'Falou brother, at√© mais!',
                'Tranquilo, na paz!',
                'Valeu, qualquer coisa √© s√≥ chamar!',
                'De boa mano, at√© depois!',
                '√â n√≥is, tipo assim, normal!'
            ];
            return this.getRandomResponse(goodbyeResponses);
        }
        
        // Perguntas sobre clima/tempo
        if (this.containsAny(lowerMessage, ['tempo', 'clima', 'chuva', 'sol', 'frio', 'calor'])) {
            const weatherResponses = [
                'Sei l√° mano, n√£o t√¥ vendo o tempo aqui. Olha no Google!',
                'Tipo assim, n√£o tenho como saber o clima agora. Confere no app!',
                'Na moral, n√£o consigo ver o tempo. D√° uma olhada no celular!',
                'Brother, t√¥ sem ver o tempo. Checa no seu app de clima!'
            ];
            return this.getRandomResponse(weatherResponses);
        }
        
        // Perguntas gen√©ricas
        if (lowerMessage.includes('?')) {
            const questionResponses = [
                'Sei l√° mano, pergunta complicada essa a√≠. Me explica melhor!',
                'Tipo assim, n√£o manjo muito disso. Me d√° mais detalhes!',
                'Na moral, n√£o sei te dizer. Mas tipo, o que voc√™ acha?',
                'Brother, t√¥ por fora dessa. Me conta mais sobre isso!'
            ];
            return this.getRandomResponse(questionResponses);
        }
        
        // Resposta padr√£o
        const defaultResponses = [
            'Interessante isso que voc√™ falou, mano.',
            'Tipo assim, me conta mais sobre isso.',
            'Na moral, que rol√™ hein!',
            'Brother, t√¥ ligado no que voc√™ t√° falando.',
            'De boa, me explica melhor ent√£o!',
            'Tranquilo, tipo assim, normal.'
        ];
        
        return this.getRandomResponse(defaultResponses);
    }
    
    containsAny(text, keywords) {
        return keywords.some(keyword => text.includes(keyword));
    }
    
    getRandomResponse(responses) {
        return responses[Math.floor(Math.random() * responses.length)];
    }
    
    getFallbackResponse(message) {
        const fallbacks = [
            'Brother, deu um bug aqui. Tenta de novo?',
            'Na moral, n√£o rolou agora. Me manda outra mensagem!',
            'Tipo assim, n√£o entendi direito. Reformula a√≠!',
            'Deu erro mano, tenta novamente!'
        ];

        return this.getRandomResponse(fallbacks);
    }
    
    // M√©todo para configurar chave da API Requesty
    setApiKey(apiKey) {
        this.apiKey = apiKey;
        this.headers.Authorization = `Bearer ${apiKey}`;
        console.log('üîë API Key atualizada para Requesty');
    }
    
    // Gera prompt otimizado para cria√ß√£o de imagem
    async generateImagePrompt(userMessage) {
        try {
            console.log('üß† Gerando prompt otimizado para imagem com base em:', userMessage);
            
            const promptSystem = `Voc√™ √© um especialista em criar prompts para IA de imagens. Sua tarefa √© converter pedidos do usu√°rio em prompts detalhados e eficazes em INGL√äS para gerar imagens de alta qualidade.

REGRAS:
- Responda APENAS com o prompt em ingl√™s, sem explica√ß√µes
- Use descri√ß√µes visuais detalhadas
- Inclua estilo art√≠stico quando apropriado
- Use termos t√©cnicos de arte/fotografia
- Seja espec√≠fico sobre cores, ilumina√ß√£o, composi√ß√£o
- M√°ximo 150 caracteres para ser eficiente

EXEMPLOS:
Entrada: "crie um gato fofo"
Sa√≠da: "cute fluffy orange cat, adorable big eyes, soft fur, natural lighting, high quality, detailed, kawaii style"

Entrada: "desenhe uma paisagem"
Sa√≠da: "beautiful landscape, rolling hills, sunset golden hour, dramatic sky, vibrant colors, cinematic composition, 4k"

Agora converta este pedido do usu√°rio em um prompt otimizado:`;

            const response = await this.generateGeminiResponse(userMessage, [], promptSystem);
            
            // Limpar e validar o prompt gerado
            let optimizedPrompt = response.trim()
                .replace(/^["'`]|["'`]$/g, '') // Remove aspas do in√≠cio/fim
                .replace(/\n|\r/g, ' ') // Remove quebras de linha
                .trim();

            // Se ficou muito curto ou n√£o foi gerado adequadamente, usar uma vers√£o b√°sica
            if (optimizedPrompt.length < 10 || optimizedPrompt.includes('n√£o posso') || optimizedPrompt.includes('desculpe')) {
                optimizedPrompt = `${userMessage}, high quality, detailed, beautiful, artistic style`;
            }

            console.log('‚ú® Prompt otimizado gerado:', optimizedPrompt);
            return optimizedPrompt;

        } catch (error) {
            console.error('‚ùå Erro ao gerar prompt de imagem:', error);
            // Fallback simples
            return `${userMessage}, high quality, detailed, beautiful artwork`;
        }
    }

    // Gera descri√ß√£o da imagem ap√≥s cria√ß√£o
    async generateImageDescription(originalRequest, generatedPrompt) {
        try {
            const promptSystem = `Voc√™ √© um assistente que comenta sobre imagens geradas. Seja casual, descolado e empolgado.

REGRAS:
- Fale como se fosse um amigo que acabou de criar algo legal
- Use g√≠rias atuais e seja natural
- Comente sobre o que foi criado baseado no prompt
- Seja breve (m√°ximo 2 frases)
- Seja empolgado mas n√£o exagere

O usu√°rio pediu: "${originalRequest}"
Foi criado com o prompt: "${generatedPrompt}"

Agora fa√ßa um coment√°rio legal sobre a imagem que foi gerada:`;

            const description = await this.generateGeminiResponse(originalRequest, [], promptSystem);
            return description.trim();

        } catch (error) {
            console.error('‚ùå Erro ao gerar descri√ß√£o:', error);
            return `Pronto! Criei essa imagem baseada no que voc√™ pediu. Ficou bacana, n√©? üé®`;
        }
    }

    // M√©todo para atualizar personalidade da IA
    updatePersonality(newPersonality) {
        this.personality = { ...this.personality, ...newPersonality };
        console.log('üé≠ Personalidade da IA atualizada:', newPersonality);
    }
}

module.exports = AIService;
